            +----------------------+
            |        OS 211        |
            |  TASK 1: SCHEDULING  |
            |    DESIGN DOCUMENT   |
            +----------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

FirstName LastName <email@domain.example>
FirstName LastName <email@domain.example>
FirstName LastName <email@domain.example>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, or notes for the
>> markers, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> A1: (5 marks)
>> Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct thread
  {
    /* Owned by thread.c. */
    tid_t tid;                          /* Thread identifier. */
    enum thread_status status;          /* Thread state. */
    char name[16];                      /* Name (for debugging purposes). */
    uint8_t *stack;                     /* Saved stack pointer. */
    int priority;                       /* Priority. */
    int base_priority;                  /* Used to reset to original priority */
    struct lock *waiting_lock;          /* The lock that the current thread is
                                           waiting for */
    struct list holding_locks;          /* List of locks that the thread holds */
    struct list_elem allelem;           /* List element for all threads list. */

    int nice;							/*Niceness value of thread*/
    int32_t recent_cpu;					/*CPU time allocated*/

    /* Shared between thread.c and synch.c. */
    struct list_elem elem;              /* List element. */

#ifdef USERPROG
    /* Owned by userprog/process.c. */
    uint32_t *pagedir;                  /* Page directory. */
#endif

    int64_t wake_up_tick;               /* To monitor of sleep_time */
    struct list_elem sleeping_thread;   /* Add to sleeping_thread_list when
                                           calling timer_sleep*/

    /* Owned by thread.c. */
    unsigned magic;                     /* Detects stack overflow. */
  };

  base_priority keeps the original priority of the thread. its value never
  changes. the value of priority is reset to base_priority whenever the current
  thread releases the lock.

  waiting_lock keeps a pointer to lock the current thread is waiting for.

  holding_locks is a pointer to a list of the locks that a thread holds.









>> A2: (10 marks)
>> Explain the data structure used to track priority donation.
>> Give a diagram that illustrates a nested donation in your structure.

---- ALGORITHMS ----

>> A3: (5 marks)
>> How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

we always add threads to the ready_list using a round robin method. Therefore

>> A4: (5 marks)
>> Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

>> A5: (5 marks)
>> Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

---- SYNCHRONIZATION ----

>> A6: (5 marks)
>> Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

---- RATIONALE ----

>> A7: (5 marks)
>> Why did you choose this design?  In what ways is it superior to
>> another design you considered?

              ADVANCED SCHEDULER
              ==================

---- DATA STRUCTURES ----

>> B1: (5 marks)
>> Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Struct members in thread.h:
  struct thread
  {
  ...
  	int nice;				                 	/*Niceness value of thread*/
     int32_t recent_cpu;		        	/*CPU time allocated*/
  ...
  }

  Static variables in thread.c:
  int32_t load_avg;                  /*Stores the system load average*/

---- ALGORITHMS ----

>> B2: (5 marks)
>> Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
0       0   0   0  63  61  58     A
4       4   0   0  62  61  59     A
8       8   0   0  61  61  59     B
12      8   4   0  61  60  59     A
16     12   4   0  60  60  59     B
20     12   8   0  60  59  59     A
24     16   8   0  59  59  59     C
28     16  12   0  59  59  58     B
32     16  12   4  59  58  58     A
36     20  12   4  58  58  58     C


>> B3: (5 marks)
>> Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behaviour of your scheduler?

The specifications only mention that the recent_cpu must be incremented
and the priority for each thread must be computed on the same timer tick.
However it does not mention in which order to do so.

In our implementation, the recent_cpu value of the current thread is
incremented first, then the priority of the threads are calculated
using this new recent_cpu value.

The values in the table above matches the behaviour of our scheduler.
The recent_cpu for the current thread is incremented after each tick,
and after every 4 ticks, the priorities for each thread is recomputed.
The highest priority thread will run unless multiple threads have the
same highest priority. In that case, the thread which has not run for
longest time since it was last scheduled will become the running thread.

>> B4: (5 marks)
>> How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> B5: (5 marks)
>> Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.

>> B6: (5 marks)
>> The assignment explains arithmetic for fixed-point mathematics in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point mathematics, that is, an abstract
>> data type and/or a set of functions or macros to manipulate
>> fixed-point numbers, why did you do so?  If not, why not?S

The fixed-point arithmetics have been implemented by creating macros for
all the operations given in the specs. This enabled the calculations to
be done within the code without having to rewrite the formulae given in
the spec every time. It also improve readability of the code since the
names of the macros clearly explain what it does. The risk of mistakes in the
calculations is also minimised compared to if the operations were
directly applied each time using the formulae in the specs since they
are only written once in the file fixed-point.h. Fixing a bug in the
operations when using macros would be much easier as we only have to modify
them in fixed-point.h.

The fixed-point arithmetic may have done by implementing
functions for each operations. However, function calls would introduce a
runtime overhead. However, when using macros, the compiler replaces them
with the actual values at compile time.
